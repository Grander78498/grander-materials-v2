#import "/src/preamble.typ": *
#set page(margin: (left: 0pt, right: 0pt, top: 0pt, bottom: 0pt))
#figure(image("/img/cursach/cursach_2025-06-01-12-09-56.png", height: 100%), caption: none)
#figure(image("/img/cursach/cursach_2025-06-01-12-23-56.png", height: 100%), caption: none)
#figure(image("/img/cursach/cursach_2025-06-01-12-24-44.png", height: 100%), caption: none)
#show: main
#show: template

#let lb = v(18pt)
#let jb = linebreak(justify: true)

#outline()

#heading([Введение], numbering: none)
В последние годы наблюдается стремительное развитие методов глубокого   обучения,   способных   эффективно   решать   задачи   в   различных   областях, включая обработку текста, изображений и графов. Предобученные модели демонстрируют более глубокое понимание контекста, стилевую согласованность и устойчивость,   особенно   на   редких   и   лексически   разнообразных   примерах. Три ключевые архитектуры — трансформеры, генеративно-состязательные сети и графовые нейронные сети — находят применение в задачах классификации музыкальных произведений, генерации аудио и   построения   рекомендательных   систем   соответственно.

Трансформеры, GAN и GNN, применённые к различным аспектам анализа и генерации музыкального контента, подчёркивают потенциал современных нейросетевых архитектур в мультимодальных задачах.  Изучение роли предобучения трансформеров   позволяет   лучше   понять   принципы   переноса   знаний   и   оптимального   использования   языковых   моделей   в   условиях   специализированных доменов.


= Трансформер

== Цель и задачи
Цель работы: применить архитектуру трансформера для решения задачи определения жанра композиции по её аудиосоставляющей.

Поставлены следующие задачи:
- изучить архитектуру трансформера
- выбрать данные для обучения и выполнить их предобработку
- выбрать архитектуру для модели и обучить модель
- интерпретировать полученные результаты

== Теоретический раздел 

=== История архитектуры
Трансформер (Transformer) --- это архитектура глубокого обучения, представленная в 2017 году в статье "Attention Is All You Need" @attention-is-all-you-need. Она изменила представление об обработке естественного языка (NLP), заменив рекуррентные (RNN) и сверточные (CNN) сети механизмами внимания (attention).  

Ключевые преимущества:  
- параллельная обработка последовательностей (в отличие от RNN) 
- умение захватывать долгосрочные зависимости благодаря self-attention 
- масштабируемость и адаптивность для задач обработки естественного языка, компьютерного зрения (CV, RL и др.)

=== Описание архитектуры
 
Основной частью архитектуры является механизм внимания, который вычисляет "важность" каждого элемента последовательности относительно других.  

Формулы Self-Attention:  

1. Входные векторы:  
Входные токены преобразуются в векторы $X in RR^(n times d_"model")$, где #jb $n$ --- длина последовательности, $d_"model"$ --- размерность.

2. Проекции запроса, ключа, значения:

Проекции запроса выполняются в соответствии с Формулой @query:

#lb
$ Q = X W^Q $<query>
#lb

Проекции ключа выполняются в соответствии с Формулой @key:

#lb
$ K = X W^K $<key>
#lb

Проекции значения выполняются в соответствии с Формулой @value:

#lb
$ V = X W^V $<value>
#lb

#print_symbols(
  [$W^Q, W^K, W^V in RR^(d_"model" times d_k)$ --- обучаемые матрицы]
)

3. Матрица внимания:
Матрица внимания представлена Формулой @attention-matrix:

#lb
$ "Attention"(Q, K, V) = "softmax"((Q K^T) / (sqrt(d_k))) V $<attention-matrix>
#lb
   
Трансформеры не имеют встроенного понимания порядка элементов, поэтому выполняется позиционное кодирование (Формулы @pos-sin - @pos-cos) @PosEnc:

#lb
$ P(k, 2i) = sin(k / (n ^ ((2i) / d))) $<pos-sin>
$ P(k, 2i + 1) = cos(k / (n ^ ((2i) / d))) "," $<pos-cos>
#linebreak()

#print_symbols(
  [pos --- позиция токена],
  [i --- размерность]
)

Общая архитектура трансформера состоит из энкодера и декодера. Энкодер состоит из нескольких идентичных слоёв, включающих в себя слои внимания, полносвязные слои (с функцией активации ReLU), а также нормализацию. Декодер имеет схожую структуру, но он максирует будущие токены при обучении, а также связывает выход энкодера со своими ключами и значениями.

Оригинальная архитектура трансформера представлена на Рисунке @transformer-architecture.
#figure(image("/img/cursach/cursach_2025-04-17-15-04-13.png", height: 65%), caption: [Оригинальная архитектура трансформера])<transformer-architecture>

Но допустимы такие архитектуры, где используется только энкодер или используется только декодер. Например, известной архитектурой, использующей только энкодер, является BERT (Bidirectional Encoder Representations), а архитектурой, использующей только декодер, является GPT (Generative Pre-trained Transformer).


== Описание данных
В качестве данных, используемых для обучения модели, взят набор из 1957 музыкальных произведений, представленных в файлах формата FLAC (Free Lossless Audio Codec) - формат хранения аудио без потери данных @flac. Данные файлы, помимо аудиосоставляющей, содержат в себе различные мета-данные --- название композиции, автор(-ы), альбом, жанр. Именно тег жанра является интересующей частью для обучения.

Ввиду большого разнообразия жанров в датасете ($> 40$ жанров) решено преобразовать названия жанров таким образом, чтобы уменьшить их количество. Для этого использовалась ручная разметка с использованием программы AIMP (Рисунок @aimp), а также автоматическая разметка, которая заменяла поджанры на родительские жанры (например, "Hard Rock" ---> "Rock").

#figure(image("/img/cursach/cursach_2025-04-18-10-17-58.png"), caption: [Пример тегов в FLAC-файле])<aimp>

Таким образом, удалось свести количество жанров до 5 основных --- рок, метал, поп, хип-хоп и джаз.

Далее проведён анализ полученных классов. Для этого построена круговая диаграмма распределения классов в датасете (Рисунок @pie-diagram):

#figure(image("/img/cursach/cursach_2025-04-17-15-26-31.png", height: 25%), caption: [Круговая диаграмма жанров])<pie-diagram>

Из диаграммы видно, что жанр "джаз" представлен слишком маленьким числом данных ($1.1%$ от всего датасета), ввиду этого принято решение убрать из датасета композиции данного жанра. Тогда оставшиеся жанры образуют сбалансированный по классам датасет.

Отобранные в итоге жанры представлены на Рисунке @result-genres.

#figure(image("/img/cursach/cursach_2025-04-17-15-48-36.png"), caption: [Жанры, представленные в данных])<result-genres>

Далее выполнена предобработка аудио-данных - из файлов взяты первые 30 секунд (если композиция длится меньше 30 секунд, то соответствующая матрица заполнялась нулями) и извлечены мел-спектрограммы с преобразованием амплитуд в децибелы (dB).

Для визуального представления данных построены волновые диаграммы нескольких композиций. На Рисунке @first-pop представлена волновая диаграмма композиции в жанре pop.

#figure(image("/img/cursach/cursach_2025-04-18-10-13-46.png", height: 16%), caption: [Волновая диаграмма композиции в жанре pop])<first-pop>

На Рисунке @first-metal представлена волновая диаграмма композции в жанре metal.
#figure(image("/img/cursach/cursach_2025-04-18-10-14-38.png"), caption: [Волновая диаграмма композиции в жанре metal])<first-metal>

На Рисунке @first-hiphop представлена волновая диаграмма композиции в жанре hip-hop.
#figure(image("/img/cursach/cursach_2025-04-18-10-14-50.png"), caption: [Волновая диаграмма композиции в жанре hip-hop])<first-hiphop>

== Обучение модели
Для задачи классификации принято решение использовать модель трансформера, где есть только энкодер-слои. Выход из слоёв энкодера подаётся на вход полносвязной сети, а затем применяется функция активации softmax для определения вероятности принадлежности к одному из 4 классов.

Итоговая архитекутра модели представлена на Рисунке @model1-architecture.

#figure(image("/img/cursach/cursach_2025-04-18-10-12-05.png", height: 35%), caption: [Итоговая архитектура модели])<model1-architecture>

Обучение производилось в течение 10 эпох, со следующими зафиксированными параметрами модели:
- размерность эмбеддингов: 128
- количество голов внимания: 4
- размерность скрытого слоя: 128
- количество энкодер-слоёв: 4
- величина dropout: 0.1

Процесс обучения продемонстрирован на Рисунке @trans-learn.

#figure(image("/img/cursach/cursach_2025-04-17-15-55-52.png"), caption: [Процесс обучения трансформера])<trans-learn>

Код обучения модели представлен в Листинге @trans-code.

== Полученные результаты

Результаты обучения представлены на Рисунке @trans-result:

#figure(image("/img/cursach/cursach_2025-04-17-15-54-55.png"), caption: [Результаты обучения трансформера])<trans-result>

Величина macro-f1 незначительно изменялась в процессе обучения --- это связано с тем, что для обучения трансформера нужно большее количество эпох, а также модель с большим числом параметров. Однако это потребует более значительных ресурсов компьютера, на котором производится обучение.

== Выводы по разделу

В ходе выполнения работы построена и обучена модель трансформера для классификации музыкальных произведений. Выяснено, что данная архитектура является хорошим инструментом для анализа аудио, однако требует существенных ресурсов и времени для обучения.

= Генеративно-состязательная нейронная сеть

== Цель и задачи
Цель работы: применить генеративно-состязательную нейронную сеть для генерации музыкальных произведений.

Поставлены следующие задачи:
- изучить устройство генеративно-состязательных нейронных сетей (GAN)
- выбрать данные для обучения и выполнить их предобработку
- обучить составленную GAN
- интерпретировать полученные результаты

== Теоретический раздел

=== История архитектуры
 
Generative Adversarial Networks (GAN) — это класс моделей глубокого обучения, представленный в 2014 году Яном Гудфеллоу и его коллегами. GAN предназначены для генерации новых данных (изображений, текста, аудио и др.) путем обучения двух конкурирующих нейронных сетей: генератора (Generator) и дискриминатора (Discriminator) @gan-book.  

Ключевые особенности GAN:  
- генерация реалистичных данных (например, фотореалистичных изображений).  
- не требуют явного моделирования распределения данных (в отличие от вариационных автоэнкодеров, VAE).  
- обучение через состязательный процесс, аналогичный игре "подделыватель vs эксперт". 

=== Описание архитектуры 

1. Генератор 
Целью генератора является преобразование случайный шум $x$ (обычно из нормального распределения $N(0,1)$) в данные, похожие на реальные. 

Архитектура обычно использует транспонированные свертки (Transposed Convolution) для апсемплинга. В современных GAN применяются ResNet-блоки или стилевые модули (StyleGAN). Также возможно применение полносвязных нейронных сетей.

2. Дискриминатор 
Цель: отличает реальные данные $x_"real"$ от сгенерированных генератором $x_"fake"$.  

Архитектура обычно использует свёрточные нейронные сети (для изображений), но возможно применение полносвязных нейронных сетей.  

Дискриминатор выдает вероятность того, насколько данные похожи на реальные. При обучении реальным данным присваивается метка, равная 1, а данным, сгенерированным генератором, присваивается метка, равная 0.

3. Функция потерь  
GAN обучаются как минимаксная игра (игра с нулевой суммой) @gan-book:

#lb
$ min_G max_D V(D, G) = EE_(x ~ p_"data"(x))[log D(x)] + EE_(z ~ p_z(z))[log(1 - D(G(z)))] $

Целью генератора является "обмануть" дискриминатор, минимизируя $log(1 - D(G(z)))$.

Целью дискриминатора является максимизировать точность классификации --- а именно, отличие между $x_"real"$ и $x_"fake"$.  

=== Вариации GAN  

1. Условные GAN (cGAN)  
Добавляют условие (класс, текст, изображение) в генератор и дискриминатор.Примеры: pix2pix (image-to-image), StyleGAN (контроль стиля).  

2. Progressive GAN  
Идеей этих сетей является постепенное наращивание разрешения (начинают с 4×4, доходят до 1024×1024). 

== Описание данных
В качестве датасета для обучения генеративно-состязательной нейронной сети выбран датасет классической музыки @gan-dataset, состоящий из отрывков произведений 19 классических композиторов, представленных в формате MIDI.

Для визуального представления аудиосоставляющей файлов построены волновые диаграммы. Для этого MIDI файлы преобразованы в формат FLAC. На Рисунке @albeniz представлена волновая диаграмма композиции Исаака Альбениса.

#figure(image("/img/cursach/cursach_2025-04-18-10-20-48.png"), caption: [Волновая диаграмма композиции Альбениса])<albeniz>

На Рисунке @beethoven представлена волновая диаграмма композиции Людвига ван Бетховена.
#figure(image("/img/cursach/cursach_2025-04-18-10-22-05.png"), caption: [Волновая диаграмма композиции Бетховена])<beethoven>

На Рисунке @albeniz представлена волновая диаграмма композиции Вольфганга Амадея Моцарта.
#figure(image("/img/cursach/cursach_2025-04-18-10-22-30.png"), caption: [Волновая диаграмма композиции Моцарта])<mozart>

== Обучение модели
Датасет, состоящий из MIDI-файлов, представляет собой одномерный массив, поэтому архитектура генератора и дискриминатора может быть сделана с помощью полносвязной сети. Но важно, чтобы в полносвязной сети в качестве функции активации использовалась LeakyReLU, чтобы гарантировался ненулевой градиент даже для отрицательных входов.

На Рисунке @generator-architecture представлена архитектура генератора.

#figure(image("/img/cursach/cursach_2025-04-18-10-26-20.png"), caption: [Архитектура генератора])<generator-architecture>

На Рисунке @discriminator-architecture представлена архитектура дискриминатора.
#figure(image("/img/cursach/cursach_2025-04-18-10-26-45.png"), caption: [Архитектура дискриминатора])<discriminator-architecture>

Код обучения GAN представлен в Листинге @gan-code.

== Полученные результаты
Результат обучения представлен на Рисунке @gan-learn.

#figure(image("/img/cursach/cursach_2025-04-17-19-32-10.png"), caption: [Результаты обучения GAN])<gan-learn>

В процессе обучения дискриминатор показал уменьшение ошибки, однако ошибка генератора нестабильно изменялась. Это связано с тем, что на начальных эпохах дискриминатор уверенно способен отличать реальные данные от сгенерированных, что влечёт к долгому обучению генератора. Однако такое поведение исправляется при увеличении количества эпох.

Для демонстрации получаемых результатов генерации сохранялись генерируемые MIDI-файлы каждую 5-ю эпоху. На Рисунке @epoch15 представлена волновая диаграмма результата генерации после 15-й эпохи.

#figure(image("/img/cursach/cursach_2025-04-18-10-29-35.png"), caption: [Результат генерации после 15-й эпохи])<epoch15>

На Рисунке @epoch30 представлена волновая диаграмма результата генерации после 30-й эпохи.
#figure(image("/img/cursach/cursach_2025-04-18-10-30-24.png"), caption: [Результат генерации после 30-й эпохи])<epoch30>

== Выводы по разделу

В ходе выполнения работы обучена генеративно-состязательная сеть для генерации музыкальных произведений. Модель показала неплохие результаты в генерации, однако для генерации более правдоподобных произведений необходимо увеличивать количество эпох.

= Графовая нейронная сеть

== Цель и задачи
Цель работы: применить графовую нейронную сеть для рекомендации песен пользователям.

Поставлены следующие задачи:
- изучить устройство графовых нейронных сетей (GNN)
- выбрать данные для обучения и выполнить их предобработку
- обучить составленную GNN
- интерпретировать полученные результаты

== Теоретический раздел
Графовые нейронные сети (Graph Neural Networks, GNN) представляют собой класс моделей глубокого обучения, разработанных для обработки данных, представленных в виде графов @GNNBook2022. В отличие от традиционных нейронных сетей, которые работают с регулярными структурами, такими как последовательности или изображения, GNN способны эффективно обрабатывать данные с произвольной топологией, где связи между объектами могут быть сложными и нерегулярными.

=== Архитектура графовых нейронных сетей

Граф состоит из узлов и связей между ними, называемых ребрами. Каждый узел и ребро могут содержать свои атрибуты. GNN обрабатывают такие структуры, последовательно агрегируя информацию от соседних узлов и обновляя их представления. Ключевые компоненты графовых нейронных сетей включают:

1. Агрегацию информации. На каждом слое сети узел собирает данные от своих соседей. Это может быть простое усреднение, суммирование или более сложные механизмы, такие как взвешивание с помощью внимания.

2. Обновление представления узла. После сбора информации от соседей узел комбинирует ее со своими текущими данными, используя нейронную сеть, например, полносвязный слой.

3. Объединение информации на уровне графа. Для задач, требующих предсказания для всего графа, информация от всех узлов объединяется в единый вектор с помощью операций суммирования, усреднения или иерархического объединения.

=== Основные типы графовых нейронных сетей

Существует несколько распространенных архитектур GNN, различающихся подходом к обработке информации:

1. Графовые сверточные сети (GCN) используют приближенную спектральную свертку, обновляя представления узлов через взвешенное усреднение информации от соседей.

2. Графовые сети с вниманием (GAT) применяют механизм внимания для динамического определения важности каждого соседа при агрегации.

3. GraphSAGE предлагает гибкий подход к агрегации, поддерживая различные методы объединения информации, включая LSTM.

4. Нейронные сети с передачей сообщений (MPNN) представляют общий фреймворк, где узлы обмениваются сообщениями перед обновлением своих состояний.

5. Графовые трансформеры адаптируют архитектуру трансформеров для работы с графами, вычисляя внимание между узлами.

=== Применение графовых нейронных сетей

GNN нашли применение в многочисленных областях:

1. В химии и биологии они используются для предсказания свойств молекул, анализа белковых структур и генерации новых соединений. 
2. В социальных сетях GNN помогают моделировать взаимодействия пользователей, выявлять сообщества и улучшать рекомендательные системы. 
3. В компьютерном зрении они применяются для анализа сцен и распознавания действий. 
4. Транспортные системы используют GNN для прогнозирования трафика и оптимизации маршрутов. 
5. В кибербезопасности эти сети помогают обнаруживать аномалии и вредоносное ПО. 
6. В обработке естественного языка GNN работают с семантическими графами и графами знаний.

=== Преимущества и ограничения

Главные преимущества GNN включают способность работать со сложными нерегулярными структурами, учитывать как атрибуты узлов, так и связи между ними, а также обеспечивать относительную интерпретируемость результатов. Однако существуют и ограничения: высокая вычислительная сложность при работе с большими графами, трудности с обобщением на новые типы графов и сложность обработки динамически изменяющихся структур.

== Описание данных

Для решения задачи построения рекомендательной системы сгенерирован синтетический датасет связей между пользователями и песнями.

Для пользователей выбрана структура, представленная на Рисунке @user-structure.

#figure(image("/img/cursach/cursach_2025-04-18-12-59-40.png", height: 20%), caption: [Структура пользователей])<user-structure>

Пример 10 первых пользователей с такой структурой представлен на Рисунке @user-gnn.

#figure(image("/img/cursach/cursach_2025-04-18-11-30-47.png"), caption: [Пример пользователей])<user-gnn>

Для песен выбрана структура, представленная на Рисунке @song-structure.

#figure(image("/img/cursach/cursach_2025-04-18-13-02-58.png"), caption: [Структура песен])<song-structure>

Пример 10 первых песен с такой структурой представлен на Рисунке @song-gnn.

#figure(image("/img/cursach/cursach_2025-04-18-11-31-48.png"), caption: [Пример песен])<song-gnn>

Для связей между пользователями и песнями выбрана структура, представленная на Рисунке @interaction-structure.

#figure(image("/img/cursach/cursach_2025-04-18-13-13-02.png"), caption: [Структура связей между пользователями и песнями])<interaction-structure>

Пример 10 первых связей с такой структурой представлен на Рисунке @interaction-gnn.

#figure(image("/img/cursach/cursach_2025-04-18-11-32-10.png"), caption: [Структура связей между пользователями и песнями])<interaction-gnn>

В условии того, что датасет сгенерирован, важно проверить, чтобы распределение жанров, одного из важнейших параметров при рекомендации песни, было близко к равномерному. Для анализа построен график распределения жанров в датасете (Рисунок @genre-gnn):
#figure(image("/img/cursach/cursach_2025-04-18-11-33-40.png"), caption: [Распределение жанров в датасете])<genre-gnn>

Данная диаграмма показывает, что жанры распределены равномерно, поэтому серьёзная предобработка, связанная с балансировкой классов, не нужна.

Код генерации данных представлен в Листинге @generate-code.

== Обучение модели

В модели сначала составляются эмбеддинги для всех полей в объектах, а затем применяются графовые свёрточные слои для анализа связей между песнями и пользователями. Выходом модели является численное предсказание, насколько сильно можно рекомендовать песню пользователю. Чем больше число на выходе, тем выше рекомендательная сила.

Построенная архитектура представлена на Рисунке @gnn-architecture.

#figure(image("/img/cursach/cursach_2025-04-18-11-34-27.png", height: 35%), caption: [Архитектура графовой нейронной сети])<gnn-architecture>

Процесс обучения графовой нейронной сети представлен на Рисунке @gnn-learn.

#figure(image("/img/cursach/cursach_2025-04-18-11-33-19.png"), caption: [Процесс обучения графовой нейронной сети])<gnn-learn>

Код обучения графовой нейронной сети представлен в Листинге @gnn-code.

== Полученные результаты

На Рисунке @gnn-loss представлен график изменения ошибки в процессе обучения.

#figure(image("/img/cursach/cursach_2025-04-18-11-34-59.png"), caption: [График ошибки при обучении])<gnn-loss>

График показывает, что в течение обучения ошибка уменьшалась --- следовательно, модель хорошо обучилась.

На Рисунке @gnn-recomendation представлены результаты рекомендации песен для случайного пользователя. Рекомендательной системе на вход подаются данные пользователя, а выходом является 5 самых рекомендуемых песен.

#figure(image("/img/cursach/cursach_2025-04-18-11-35-22.png"), caption: [Результаты рекомендации])<gnn-recomendation>

== Выводы по разделу
В ходе выполнения работы обучена графовая нейронная сеть для построения музыкальной рекомендательной системы. Выяснено, что GNN отлично справляется с задачей анализа связей между объектами, которая является ключевой для построения рекомендательных систем.

= Сравнительный анализ свёрточных нейронных сетей и трансформеров в задаче классификации музыкальных произведений
== Цель и задачи
Цель работы: сравнить результаты применения свёрточных нейронных сетей и трансформеров в задаче классификации музыкальных произведений по жанрам.

Поставлены следующие задачи:
- изучить устройство генеративно-состязательных нейронных сетей (GAN)
- выбрать данные для обучения и выполнить их предобработку
- обучить составленную GAN
- интерпретировать полученные результаты

Актуальность: задача классификации музыкальных произведений по жанрам может найти своё применение в стриминговых сервисах при автоматическом определении жанров и составлении жанровых плейлистов. Также данная задача может быть полезна как подзадача для создания музыкальной рекомендательной системы.

== Теоретический раздел

=== Применение свёрточных нейронных сетей

Свёрточные нейронные сети изначально разрабатывались для обработки изображений, но их успешно адаптируют для работы с аудиоданными. В задаче классификации музыки CNN применяются для автоматического извлечения признаков из звуковых сигналов и последующего определения жанра, настроения или других характеристик композиции.  

1. Преобразование аудиосигнала в подходящий формат  
Музыкальный сигнал --- это временной ряд, но CNN эффективнее работают с двумерными представлениями. Для этого используют:  
- спектрограммы (STFT --- кратковременное преобразование Фурье), которые отображают изменение частотного спектра во времени 
- мел-спектрограммы --- вариант спектрограммы, учитывающий особенности человеческого слуха (логарифмическая шкала частот)  
- хромаграммы --- акцентируют гармонические компоненты, полезны для анализа аккордов и тональности

2. Архитектура CNN для классификации музыки  
Типичная архитектура включает:  
- свёрточные слои --- обнаруживают локальные паттерны в спектрограммах (например, ритмические или гармонические структуры) 
- пулинговые слои (MaxPooling, AveragePooling) — уменьшают размерность, сохраняя важные признаки 
- полносвязные слои — выполняют финальную классификацию
- дополнительно могут применяться Batch Normalization и Dropout для улучшения обучения 

3. Особенности обучения  
- аугментация данных: для увеличения размера выборки применяют pitch shifting, time stretching, добавление шума
- Transfer learning: использование предобученных на изображениях моделей (например, VGG или ResNet) с дообучением на спектрограммах 
- многоканальные входы: иногда используют несколько типов спектрограмм (например, мел-спектрограмму и хромаграмму) как разные каналы, аналогично RGB в изображениях

4. Преимущества CNN для классификации музыки  
- автоматическое извлечение признаков без ручной разработки (в отличие от традиционных методов, использующих MFCC или другие hand-crafted features)  
- устойчивость к небольшим искажениям и вариациям в данных
- возможность комбинирования с другими архитектурами (например, RNN для учёта временных зависимостей) 

5. Ограничения  
- требуется большой размеченный датасет для обучения
- высокая вычислительная сложность, особенно при высоком разрешении спектрограмм
- потеря временной информации при использовании только CNN (решается гибридными моделями с LSTM или Transformer) 

CNN доказали свою эффективность в задачах музыкальной классификации, особенно при работе с спектрограммами как с изображениями @conv-audio. Дальнейшее развитие связано с улучшением архитектур, использованием самообучения и многомодальных подходов.

=== Применение трансформеров

Трансформеры, изначально разработанные для обработки естественного языка (NLP), успешно адаптируются для работы с аудиоданными благодаря их способности моделировать долгосрочные зависимости в последовательностях. В задаче классификации музыки трансформеры используются для анализа временных и частотных закономерностей в аудиосигналах, что позволяет точно определять жанр, настроение, исполнителя и другие характеристики.  

1. Преобразование аудиосигнала для трансформеров

Трансформеры работают с последовательностями токенов, поэтому аудио предварительно обрабатывается одним из способов:  
- разделение на перекрывающиеся сегменты (патчи) и линейное проецирование в эмбеддинги (аналогично Vision Transformer для изображений)
- использование спектрограмм (мел-спектрограммы, спектры STFT) с последующей токенизацией
- применение learnable-фичей (например, CNN-блоков) для получения компактного представления перед трансформером

2. Архитектура трансформера для классификации музыки

Основные компоненты:  
- энкодер трансформера — анализирует последовательность аудио-токенов с помощью механизма самовнимания (self-attention)
- Positional embeddings — добавляют информацию о временной позиции сегментов (важно для аудио, где порядок принципиален)
- классификационная голова — обычно линейный слой поверх [CLS]-токена или усреднённых эмбеддингов.  
- возможны модификации: использование иерархических трансформеров для разных масштабов времени.  

Для проверки трансформера принято решение дообучать уже существующую модель, поскольку обучение трансформера с нуля требует значительных ресурсов и больших датасетов. В качестве предобученной модели выбран DistilHuBERT.  

DistilHuBERT --- это дистиллированная (упрощённая) версия HuBERT, обученная на самообучении с аудиоданными LibriSpeech.  

Преимуществами модели являются:  
- перенос знаний: модель уже умеет извлекать универсальные аудио-фичи
- экономия ресурсов: дообучение головы классификатора требует мало данных и времени  
- хорошее качество даже на небольших датасетах

Недостатками модели являются:  
- ограниченная гибкость (архитектура фиксирована).  
- возможна избыточность для простых задач

== Описание используемых данных

В качестве датасета взят датасет GTZAN @gtzan-dataset, который содержит в себе музыкальные отрывки длиной в 30 секунд. В датасете представлены композиции 10 разных жанров.

Для анализа распределения жанров построена столбчатая диаграмма (Рисунок @genre-4).

#figure(image("/img/cursach/cursach_2025-04-18-11-45-35.png"), caption: [Распределение жанров в датасете])<genre-4>

Из диаграммы видно, что все жанры представлены равномерно, с небольшим уточнением --- одна композиция в жанре jazz имеет некорретный файл, поэтому данный жанр представлен 999 композициями вместо 1000 у других жанров.

Далее проведён анализ волновых диаграмм различных диаграмм. На Рисунке @blues-4 представлена волновая диаграмма композиции в жанре blues.

#figure(image("/img/cursach/cursach_2025-04-18-11-44-14.png"), caption: [Волновая диаграмма композиции в жанре blues])<blues-4>

На Рисунке @disco-4 представлена волновая диаграмма композиции в жанре disco.

#figure(image("/img/cursach/cursach_2025-04-18-11-44-40.png"), caption: [Волновая диаграмма композиции в жанре disco])<disco-4>

На Рисунке @metal-4 представлена волновая диаграмма композиции в жанре metal.

#figure(image("/img/cursach/cursach_2025-04-18-11-45-11.png", height: 25%), caption: [Волновая диаграмма композиции в жанре metal])<metal-4>

Из представленных диаграмм можно сделать вывод, что композиции в жанре metal обладают высокой громкостью, а композиции других жанров обладают разнообразием в плане динамики.

== Свёрточная нейронная сеть

=== Обучение модели

На Рисунке @cnn-architecture представлена архитектура составленной свёрточной нейронной сети.

#figure(image("/img/cursach/cursach_2025-04-18-11-50-02.png"), caption: [Архитектура свёрточной нейронной сети])<cnn-architecture>

Код обучения свёрточной нейронной сети представлен в Листинге @cnn-code.

=== Полученные результаты

На Рисунке @cnn-loss представлен график изменения ошибки в процессе обучения модели.

#figure(image("/img/cursach/cursach_2025-04-18-11-48-46.png", height: 20%), caption: [Ошибка при обучении свёрточной нейронной сети])<cnn-loss>

На Рисунке @cnn-f1 представлен график изменения f1-score в процессе обучения.

#figure(image("/img/cursach/cursach_2025-04-18-11-49-12.png"), caption: [F1-score при обучении свёрточной нейронной сети])<cnn-f1>

Графики показывают, что модель хорошо обучается, однако итоговый f1-score не является высоким. Это возможно исправить с помощью увеличения количества эпох, однако это потребует значительных временных ресурсов для обучения.

== Трансформер

=== Обучение модели

На Рисунке @fine-tune представлено время дообучения модели DistilHuBERT.

#figure(image("/img/cursach/cursach_2025-04-18-11-55-07.png"), caption: [Процесс дообучения трансформера])<fine-tune>

Код дообучения трансформера представлен в Листинге @finetune-code.

=== Полученные результаты

На Рисунке @hubert-loss представлен график изменения ошибки при дообучении.

#figure(image("/img/cursach/cursach_2025-04-18-11-46-47.png"), caption: [Ошибка при дообучении трансформера])<hubert-loss>

На Рисунке @hubert-f1 представлен график изменения f1-score при дообучении.
#figure(image("/img/cursach/cursach_2025-04-18-11-47-47.png"), caption: [F1-score при дообучении трансформера])<hubert-f1>

Графики показывают, что модель отлично дообучилась на датасете, показав высокий f1-score = 0.85, обучаясь всего 10 эпох.

== Выводы по разделу

В результате сравнения можно сделать вывод, что свёрточные нейронные сети требуют меньше ресурсов для обучения, однако их точность ниже. В то же время, трансформер лучше справляется с задачей анализа музыкальных произведений ввиду того, что способны анализировать временную информацию, но есть проблемы с тем, что нужно много ресурсов для обучения, а при обучении с нуля нужно большое количество эпох обучения и датасет с огромным количеством данных.

#heading([Заключение], numbering: none)
Хотя трансформеры, GAN и GNN ориентированы на разные типы задач и структур данных, между ними можно провести множество параллелей. Все эти подходы стремятся строить более глубокие и выразительные представления информации — будь то текст, изображения или графы. Их объединяет стремление уловить скрытые зависимости и структуры, чтобы принимать более точные решения или генерировать качественные данные.

Интересной областью становится их комбинирование: например, трансформеры могут применяться к графам, GAN'ы могут использовать графовые структуры для генерации сложных объектов (например, молекул), а GNN используются для генерации структурированных данных. Эти подходы можно эффективно сочетать, чтобы использовать преимущества каждого.


#bibliography("authors.bib", style: "/src/gost-r-7-0-5-2008-numeric-alphabetical.csl", title: [Список использованных источников])

#appendix()

#set heading(offset: 5)
= Реализация трансформера
#simple-code(
  raw(read("trans_learn.py")),
  [Код трансформера],
  label: <trans-code>
)
= Реализация генеративной нейронной сети
#simple-code(
  raw(read("gan.py")),
  [Код генеративной нейронной сети],
  label: <gan-code>
)
= Реализация графовой нейронной сети
#simple-code(
  raw(read("generate.py")),
  [Код генерации синтетических данных],
  label: <generate-code>
)
#simple-code(
  raw(read("gnn.py")),
  [Код графовой нейронной сети],
  label: <gnn-code>
)
= Реализация свёрточной нейронной сети
#simple-code(
  raw(read("cnn.py")),
  [Код свёрточной нейронной сети],
  label: <cnn-code>
)

= Реализация дообучения трансформера
#simple-code(
  raw(read("hubert.py")),
  [Код дообучения модели трансформера],
  label: <finetune-code>
)